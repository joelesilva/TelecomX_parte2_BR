# Telecom X ‚Äî Previs√£o de Churn (Parte 2)

Projeto de ci√™ncia de dados para prever a evas√£o (churn) de clientes da empresa fict√≠cia Telecom X. O trabalho est√° estruturado em um notebook com pipeline completo: explora√ß√£o e limpeza dos dados, pr√©-processamento (encode, imputa√ß√£o, normaliza√ß√£o), balanceamento de classes (SMOTE), divis√£o treino/teste, treinamento de modelos e avalia√ß√£o com m√©tricas de classifica√ß√£o.

## Vis√£o Geral
- Objetivo: identificar clientes com alta probabilidade de cancelar o servi√ßo para orientar a√ß√µes de reten√ß√£o.
- Entrada: dataset tabular `df_limpo.csv` (7.043 linhas, 22 colunas inicialmente).
- Sa√≠da: modelos treinados e avalia√ß√£o por m√©tricas (accuracy, precision, recall, f1), relat√≥rios e matrizes de confus√£o gerados no notebook.

## Estrutura do Reposit√≥rio
- `prediction_telecom_x.ipynb`: notebook principal com todo o pipeline.
- `df_limpo.csv`: dataset limpo utilizado no notebook.

## Dados
- Dimens√£o: 7.043 linhas, 22 colunas (21 ap√≥s remo√ß√µes iniciais).
- Vari√°vel alvo: `Churn` (Yes/No), convertida para bin√°ria (Yes=1, No=0).
- Colunas (amostra/agrupadas por dom√≠nio):
  - Identifica√ß√£o: `customerID` (removida na limpeza inicial)
  - Cliente: `customer.gender`, `customer.SeniorCitizen`, `customer.Partner`, `customer.Dependents`, `customer.tenure`
  - Telefone: `phone.PhoneService`, `phone.MultipleLines`
  - Internet: `internet.InternetService`, `internet.OnlineSecurity`, `internet.OnlineBackup`, `internet.DeviceProtection`, `internet.TechSupport`, `internet.StreamingTV`, `internet.StreamingMovies`
  - Conta/Pagamento: `account.Contract`, `account.PaperlessBilling`, `account.PaymentMethod`, `account.Charges.Monthly`, `account.Charges.Total`
  - Valor agregado: `Total.Day`
- Classes antes do balanceamento: No=5.174 (73,46%), Yes=1.869 (26,54%).

## Ambiente e Depend√™ncias
Recomendado Python 3.9+.

Depend√™ncias principais utilizadas no notebook:
- pandas, numpy
- matplotlib, seaborn
- scikit-learn (preprocessing, model_selection, metrics, modelos)
- imbalanced-learn (SMOTE)
- Jupyter (para executar o notebook)

Instala√ß√£o r√°pida (ambiente virtual opcional):

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install jupyter pandas numpy scikit-learn imbalanced-learn matplotlib seaborn
```

Abrir o notebook:
```bash
jupyter notebook prediction_telecom_x.ipynb
```

## Pipeline (Notebook)
1. Carregamento e inspe√ß√£o inicial do dataset.
2. Limpeza: remo√ß√£o de `customerID`; checagem e imputa√ß√£o m√≠nima de valores ausentes (mediana para num√©ricos, moda para categ√≥ricos, quando necess√°rio).
3. EDA: taxa de churn, contagens e distribui√ß√µes com visualiza√ß√µes.
4. Pr√©-processamento:
   - Label Encoding para vari√°veis categ√≥ricas (mapeamentos registrados e impressos no notebook).
   - Duas vers√µes de features: sem normaliza√ß√£o (`X_no_scale`) e com normaliza√ß√£o `StandardScaler` (`X_scaled`).
5. Balanceamento: aplica√ß√£o de SMOTE (random_state=42) devido a desbalanceamento (ratio ‚âà 0,36), gerando conjuntos balanceados 50/50.
6. Divis√£o treino/teste: `train_test_split` estratificado (test_size=0,25, random_state=42) para vers√µes escaladas e n√£o escaladas.
7. Modelagem (tr√™s modelos):
   - Logistic Regression (com dados escalados).
   - Random Forest (sem escala ‚Äî √°rvores s√£o invariantes a escala).
   - K-Nearest Neighbors (K=5, com dados escalados).
8. Avalia√ß√£o: accuracy, precision, recall, f1-score, relat√≥rio de classifica√ß√£o e matriz de confus√£o; compara√ß√£o treino vs. teste para diagn√≥stico de over/underfitting.

### Prepara√ß√£o dos Dados ‚Äî Detalhes
- Classifica√ß√£o de vari√°veis (detectadas automaticamente no notebook):
  - Num√©ricas: `customer.SeniorCitizen`, `customer.tenure`, `Total.Day`, `account.Charges.Monthly`, `account.Charges.Total`.
  - Categ√≥ricas: `customer.gender`, `customer.Partner`, `customer.Dependents`, `phone.PhoneService`, `phone.MultipleLines`, `internet.InternetService`, `internet.OnlineSecurity`, `internet.OnlineBackup`, `internet.DeviceProtection`, `internet.TechSupport`, `internet.StreamingTV`, `internet.StreamingMovies`, `account.Contract`, `account.PaperlessBilling`, `account.PaymentMethod`.
- Codifica√ß√£o: Label Encoding por coluna categ√≥rica com registro dos mapeamentos nos outputs do notebook.
- Normaliza√ß√£o: `StandardScaler` aplicado na vers√£o escalada de `X` (para modelos sens√≠veis √† escala).
- Split: `train_test_split` estratificado (25% teste), com `random_state=42`.

### Justificativas de Modelagem
- Regress√£o Log√≠stica: modelo linear que se beneficia de dados padronizados (converg√™ncia e estabilidade da otimiza√ß√£o).
- Random Forest: baseado em √°rvores; pouco sens√≠vel √† escala, por isso treinado sem normaliza√ß√£o.
- KNN: dist√¢ncia euclidiana √© afetada por escala; normaliza√ß√£o √© essencial para comparabilidade entre atributos.
- SMOTE: aplicado para corrigir desbalanceamento significativo (26,5% vs 73,5%).
- Split estratificado: preserva a propor√ß√£o das classes em treino e teste.

### EDA e Insights
- Taxa de churn (propor√ß√£o): No 73,46% | Yes 26,54%.
- Visualiza√ß√µes geradas no notebook (inline):
  - Distribui√ß√µes/contagens por categoria (seaborn/matplotlib).
  - Matriz de correla√ß√£o entre vari√°veis num√©ricas e destaque para as mais correlacionadas com `Churn` (listadas no output do notebook).
- Observa√ß√£o: as figuras s√£o exibidas no pr√≥prio notebook; n√£o h√° pasta dedicada de imagens neste reposit√≥rio. Caso deseje export√°-las, salve-as via `plt.savefig(...)` nas c√©lulas correspondentes.

## Resultados Principais (Teste)
- Logistic Regression (dados escalados):
  - Accuracy: 0,7727 | Precision: 0,7747 | Recall: 0,7727 | F1: 0,7723
  - Gap Treino‚ÄìTeste: 0,0021 (bom ajuste; sem sinais claros de over/underfitting).
- Random Forest (sem escala):
  - Accuracy: 0,8485 | Precision: 0,8487 | Recall: 0,8485 | F1: 0,8485
  - Gap Treino‚ÄìTeste: 0,1502 (alerta de poss√≠vel overfitting; acur√°cia de treino muito alta).
- K-Nearest Neighbors (dados escalados):
  - Accuracy: 0,7859 | Precision: 0,8048 | Recall: 0,7859 | F1: 0,7825
  - Gap Treino‚ÄìTeste: 0,0634 (poss√≠vel overfitting moderado).

Observa√ß√µes:
- Random Forest obteve melhor resultado em teste entre os tr√™s, por√©m com forte ind√≠cio de overfitting (sugere regulariza√ß√£o/ajuste de hiperpar√¢metros).
- SMOTE contribuiu para balancear classes; m√©tricas reportadas consideram conjuntos balanceados e divis√£o estratificada.

## Como Reproduzir
1. Crie e ative o ambiente, instale depend√™ncias (se√ß√£o ‚ÄúAmbiente e Depend√™ncias‚Äù).
2. Abra `prediction_telecom_x.ipynb` no Jupyter.
3. Execute as c√©lulas em ordem (Kernel ‚Üí Restart & Run All) para reproduzir limpeza, pr√©-processamento, treinamento e avalia√ß√£o.

Notas sobre dados:
- O notebook espera o arquivo `df_limpo.csv` no diret√≥rio raiz do projeto (mesmo n√≠vel do notebook). O carregamento √© feito com `pd.read_csv('df_limpo.csv')`.

Seeds e reprodutibilidade:
- SMOTE: `random_state=42`
- train_test_split: `random_state=42`
- Modelos: quando aplic√°vel, `random_state=42`

================================================================================
CONCLUS√ÉO ESTRAT√âGICA - PREVIS√ÉO DE CHURN TELECOM X
================================================================================

üèÜ COMPARA√á√ÉO E SELE√á√ÉO DO MELHOR MODELO
--------------------------------------------------
Modelo Escolhido: Random Forest
F1-Score: 0.8485
Acur√°cia: 0.8485
Precis√£o: 0.8487
Recall: 0.8485

Justificativa da escolha:
‚Ä¢ Excelente capacidade de lidar com dados n√£o-lineares
‚Ä¢ Robusto a outliers e n√£o requer normaliza√ß√£o
‚Ä¢ Fornece import√¢ncia clara das vari√°veis
‚Ä¢ Menor risco de overfitting devido ao ensemble

üìä Resumo Comparativo:
                     accuracy precision    recall  f1_score
Logistic Regression   0.77271  0.774704   0.77271  0.772302
Random Forest        0.848473  0.848688  0.848473  0.848451
KNN                  0.785852  0.804755  0.785852  0.782493


üîç FATORES MAIS RELEVANTES PARA EVAS√ÉO
--------------------------------------------------
Baseado na an√°lise do Random Forest (Top 5):
‚Ä¢ account.Contract: 0.1308 (13.1%)
‚Ä¢ account.Charges.Total: 0.1169 (11.7%)
‚Ä¢ account.Charges.Monthly: 0.1142 (11.4%)
‚Ä¢ customer.tenure: 0.1122 (11.2%)
‚Ä¢ Total.Day: 0.1040 (10.4%)

Baseado na Regress√£o Log√≠stica (Top 5 por impacto):
‚Ä¢ customer.tenure: -1.4439 (DIMINUI churn)
‚Ä¢ account.Charges.Monthly: 0.8995 (AUMENTA churn)
‚Ä¢ account.Charges.Total: 0.6828 (AUMENTA churn)
‚Ä¢ account.Contract: -0.6321 (DIMINUI churn)
‚Ä¢ phone.PhoneService: -0.2870 (DIMINUI churn)


üí° INSIGHTS DE NEG√ìCIO
--------------------------------------------------
Com base na an√°lise dos dados e modelos, identificamos que:

1. PADR√ïES DE COMPORTAMENTO:
   ‚Ä¢ Clientes com contratos mensais t√™m maior propens√£o ao churn
   ‚Ä¢ Tempo de relacionamento (tenure) √© um fator cr√≠tico
   ‚Ä¢ Valor total gasto influencia significativamente a reten√ß√£o
   ‚Ä¢ Servi√ßos adicionais (seguran√ßa, backup) impactam na fideliza√ß√£o

2. PERFIL DE RISCO:
   ‚Ä¢ Clientes novos (baixo tenure) = ALTO RISCO
   ‚Ä¢ Contratos mensais = ALTO RISCO
   ‚Ä¢ Baixo valor total gasto = M√âDIO/ALTO RISCO
   ‚Ä¢ Sem servi√ßos adicionais = M√âDIO RISCO


üéØ ESTRAT√âGIAS DE RETEN√á√ÉO PROPOSTAS
--------------------------------------------------

1. ESTRAT√âGIAS PREVENTIVAS (Clientes de Alto Risco):
   ‚úì Programa de boas-vindas para novos clientes (primeiros 6 meses)
   ‚úì Incentivos para migra√ß√£o de contratos mensais para anuais
   ‚úì Ofertas personalizadas de servi√ßos adicionais
   ‚úì Contato proativo nos primeiros 90 dias

2. ESTRAT√âGIAS REATIVAS (Clientes Identificados pelo Modelo):
   ‚úì Campanhas de reten√ß√£o direcionadas
   ‚úì Descontos tempor√°rios ou upgrades gratuitos
   ‚úì Melhoria no atendimento e suporte t√©cnico
   ‚úì Pesquisas de satisfa√ß√£o e feedback

3. ESTRAT√âGIAS DE LONGO PRAZO:
   ‚úì Programa de fidelidade com benef√≠cios crescentes
   ‚úì Melhoria cont√≠nua dos servi√ßos baseada em feedback
   ‚úì Inova√ß√£o em produtos e servi√ßos
   ‚úì Experi√™ncia do cliente omnichannel


üìà IMPLEMENTA√á√ÉO E MONITORAMENTO
--------------------------------------------------

1. IMPLEMENTA√á√ÉO DO MODELO:
   ‚Ä¢ Usar o modelo Random Forest para scoring mensal
   ‚Ä¢ Definir threshold de risco (ex: probabilidade > 0.7 = alto risco)
   ‚Ä¢ Integrar com CRM para a√ß√µes autom√°ticas
   ‚Ä¢ Treinar equipe de reten√ß√£o nos insights do modelo

2. M√âTRICAS DE ACOMPANHAMENTO:
   ‚Ä¢ Taxa de churn mensal/trimestral
   ‚Ä¢ Efetividade das campanhas de reten√ß√£o
   ‚Ä¢ ROI das estrat√©gias implementadas
   ‚Ä¢ Satisfa√ß√£o do cliente (NPS)

3. MELHORIA CONT√çNUA:
   ‚Ä¢ Re-treinar modelo trimestralmente
   ‚Ä¢ A/B testing das estrat√©gias de reten√ß√£o
   ‚Ä¢ Incorporar novas vari√°veis (comportamentais, sazonais)
   ‚Ä¢ Feedback loop: resultados ‚Üí ajustes ‚Üí nova implementa√ß√£o


üéØ IMPACTO ESPERADO
--------------------------------------------------
Com base no desempenho do modelo Random Forest:
‚Ä¢ Precis√£o de 84.9%: 84.9% dos clientes identificados como risco realmente far√£o churn
‚Ä¢ Recall de 84.8%: 84.8% dos clientes que far√£o churn ser√£o identificados

Estimativa de impacto:
‚Ä¢ Redu√ß√£o potencial de 15-25% na taxa de churn
‚Ä¢ ROI estimado: 3:1 a 5:1 (cada R$ investido retorna R$ 3-5)
‚Ä¢ Melhoria na satisfa√ß√£o do cliente
‚Ä¢ Aumento do Customer Lifetime Value (CLV)

## Boas Pr√°ticas e Pr√≥ximos Passos
- Tuning e valida√ß√£o:
  - Aplicar `GridSearchCV`/`RandomizedSearchCV` e valida√ß√£o cruzada estratificada para RF, LR e KNN.
  - Considerar m√©tricas adicionais (ROC-AUC, PR-AUC), especialmente em cen√°rios desbalanceados.
- Regulariza√ß√£o e complexidade:
  - RF: reduzir profundidade, ajustar `n_estimators`, `max_features`, `min_samples_*` para mitigar overfitting.
  - LR: avaliar penaliza√ß√µes (`l2`, `l1`) e `C`.
  - KNN: calibrar `n_neighbors`, dist√¢ncia e pondera√ß√£o.
- Pipeline e produ√ß√£o:
  - Encapsular pr√©-processamento + modelo em `Pipeline` do scikit-learn.
  - Persistir artefatos (encoders/scalers/modelos) via `joblib`.
  - Criar API (FastAPI/Flask) e script de infer√™ncia para uso em produ√ß√£o.
- Dados e features:
  - Avaliar engenharia de atributos, sele√ß√£o de features e tratamento de outliers.
  - Monitorar drift de dados e desempenho em produ√ß√£o.

## Limita√ß√µes
- O notebook utiliza Label Encoding para categ√≥ricas; para alguns modelos lineares, `OneHotEncoder` pode ser mais apropriado.
- Resultados podem variar conforme ambiente (vers√µes de libs) e hardware; use as vers√µes indicadas quando poss√≠vel.

## Cr√©ditos e Licen√ßa
- Dados: `df_limpo.csv` inclu√≠do no reposit√≥rio (fonte n√£o especificada no projeto).
- Este reposit√≥rio n√£o define uma licen√ßa expl√≠cita. Adicione uma licen√ßa (por exemplo, MIT) se desejar compartilhar/redistribuir.

---
D√∫vidas ou melhorias? Abra uma issue ou sugira um PR.
